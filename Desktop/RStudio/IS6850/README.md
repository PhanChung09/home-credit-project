# Home Credit Default Risk - Data Preparation & Feature Engineering

[![R](https://img.shields.io/badge/R-4.5.1-blue.svg)](https://www.r-project.org/)
[![License](https://img.shields.io/badge/License-Educational-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-success.svg)](https://github.com)

A comprehensive, production-ready data preparation and feature engineering pipeline for credit default risk prediction. This project includes exploratory data analysis, automated feature engineering, and complete documentation.

## ğŸ“Š Project Overview

This repository implements a complete data science workflow for the Home Credit Default Risk competition. Starting with raw application data and supplementary files, the pipeline performs thorough EDA and creates 97 engineered features optimized for machine learning models.

### Key Achievements
- ğŸ” **Comprehensive EDA**: 1,003 lines of exploratory analysis with visualizations
- ğŸ”§ **Feature Engineering**: 97 new features from 5 data sources
- ğŸ“ˆ **80% Feature Increase**: From 122 to 219 features
- âœ… **Data Quality**: Fixed anomalies, handled missing values
- ğŸ¯ **Production Ready**: Modular, documented, tested code

## ğŸ“ Repository Structure

```
home-credit-feature-engineering/
â”‚
â”œâ”€â”€ ğŸ“Š EDA_homecredit_short.qmd          # Exploratory Data Analysis (38 KB)
â”‚   â”œâ”€ Missing value analysis
â”‚   â”œâ”€ Distribution visualizations  
â”‚   â”œâ”€ Anomaly detection
â”‚   â””â”€ Feature insights
â”‚
â”œâ”€â”€ ğŸ”§ feature_engineering.R             # Main data preparation script (12.5 KB)
â”‚   â”œâ”€ 6 modular functions
â”‚   â”œâ”€ 97 engineered features
â”‚   â”œâ”€ Processes 5 data sources
â”‚   â””â”€ Train/test consistency
â”‚
â”œâ”€â”€ ğŸ“– README.md                         # This file
â”œâ”€â”€ ğŸ“„ README_feature_engineering.md     # Detailed feature documentation
â”œâ”€â”€ ğŸ“ QUICK_REFERENCE.md               # Quick start guide
â””â”€â”€ âš™ï¸  .gitignore                       # Git configuration
```

## ğŸ” Exploratory Data Analysis

**File:** `EDA_homecredit_short.qmd` (Quarto document)

### Key Findings from EDA:
- **Target Imbalance**: 8% default rate (class imbalance issue)
- **DAYS_EMPLOYED Anomaly**: 365243 placeholder in 18% of records
- **Missing Data**: EXT_SOURCE_1 (56.4%), EXT_SOURCE_3 (19.8%)
- **Income Distribution**: Right-skewed with outliers
- **Credit Amounts**: Wide range requiring log transformation
- **Correlations**: External scores highly predictive

### EDA Outputs:
âœ“ Data structure summary  
âœ“ Missing value heatmaps  
âœ“ Target variable analysis  
âœ“ Univariate distributions  
âœ“ Bivariate relationships  
âœ“ Correlation matrices  
âœ“ Outlier detection  
âœ“ Data quality recommendations  

**To render the EDA:**
```r
library(quarto)
quarto_render("EDA_homecredit_short.qmd")
# Opens HTML report in browser
```

## ğŸš€ Quick Start

### Prerequisites
```r
# Install required packages
install.packages(c("data.table", "dplyr", "ggplot2", "quarto"))
```

### Basic Usage
```r
# 1. Load the pipeline
source("feature_engineering.R")

# 2. Set your data directory
data_dir <- "path/to/your/home-credit-data"

# 3. Run complete pipeline (processes all files)
results <- run_feature_engineering_pipeline(data_dir, save_output = TRUE)

# 4. Access processed data
train <- results$train      # 307,511 Ã— 219 features
test <- results$test        # 48,744 Ã— 218 features
bureau_agg <- results$bureau_agg
prev_agg <- results$prev_agg
install_agg <- results$install_agg

# 5. Check results
dim(train)
summary(train$TARGET)
names(train) %>% grep("RATIO", ., value = TRUE)
```

## ğŸ“ˆ Data Transformation Summary

| Dataset       | Original | Processed | Features Added | Improvement |
|---------------|----------|-----------|----------------|-------------|
| **Training**  | 122 cols | 219 cols  | +97           | +80%        |
| **Test**      | 121 cols | 218 cols  | +97           | +80%        |
| **Rows**      | 307,511  | 307,511   | No reduction  | Maintained  |

### Processing Time
- **EDA Rendering**: ~2-3 minutes
- **Feature Engineering**: ~2-3 minutes  
- **Total Pipeline**: ~5-6 minutes on standard hardware

### Output Files
- `application_train_processed.csv` (337 MB)
- `application_test_processed.csv` (55 MB)

## ğŸ”§ Engineered Features (97 Total)

### 1. Demographic Features (4)
- `AGE_YEARS`: Age in years (from DAYS_BIRTH)
- `EMPLOYED_YEARS`: Employment duration in years
- `REGISTRATION_YEARS`: Registration age
- `ID_PUBLISH_YEARS`: ID publication age

### 2. Financial Ratios (10)
- `CREDIT_INCOME_RATIO`: Debt burden indicator
- `PAYMENT_BURDEN`: Monthly payment affordability
- `INCOME_ANNUITY_RATIO`: Payment capacity
- `CREDIT_GOODS_RATIO`: Financing ratio
- `DOWN_PAYMENT_RATIO`: Down payment percentage
- `INCOME_PER_PERSON`: Family income adequacy
- `CREDIT_PER_CHILD`: Per-child credit burden
- `EMPLOYMENT_RATIO`: Employment stability
- `CREDIT_TERM_YEARS`: Loan duration
- `ANNUITY_CREDIT_RATIO`: Payment structure

### 3. Credit History - Bureau Features (23)
From `bureau.csv` aggregated to applicant level:
- Credit counts (active, closed, sold)
- Credit type diversity
- Overdue amounts (mean, max, sum)
- Debt amounts and ratios
- Credit history timeline
- Prolongation patterns
- Debt-to-credit ratios

### 4. Application History (24)
From `previous_application.csv`:
- Application counts by status
- Approval/refusal rates
- Credit and application amounts
- Down payment patterns
- Days to decision statistics
- Loan type distribution (cash/consumer/revolving)

### 5. Payment Behavior (17)
From `installments_payments.csv`:
- Late payment counts and rates
- Payment differences (over/underpayment)
- Days late statistics
- Payment compliance ratios
- Payment amount patterns

### 6. Missing Value Indicators (8)
- `EXT_SOURCE_1_MISSING`, `EXT_SOURCE_2_MISSING`, `EXT_SOURCE_3_MISSING`
- `OWN_CAR_AGE_MISSING`, `AMT_GOODS_PRICE_MISSING`
- `AMT_ANNUITY_MISSING`, `CNT_FAM_MEMBERS_MISSING`
- `DAYS_LAST_PHONE_CHANGE_MISSING`

### 7. Interaction Features (6)
- `AGE_INCOME_INTERACTION`: Life-stage income
- `EXT_SOURCE_MEAN`: Composite external score
- `EXT_SOURCE_12_INTERACTION`, `EXT_SOURCE_23_INTERACTION`
- `EDUCATION_INCOME_INTERACTION`
- `OCCUPATION_INCOME_INTERACTION`

### 8. Binned Variables (3)
- `AGE_GROUP`: 6 age brackets (18-25, 26-35, etc.)
- `INCOME_BIN`: 5 income levels (Low to High)
- `CREDIT_BIN`: 5 credit amount categories

### 9. Aggregated Features (1)
- `TOTAL_DOCUMENTS`: Sum of all document submission flags

## ğŸ› ï¸ Data Quality Improvements

| Issue | Impact | Solution |
|-------|--------|----------|
| **DAYS_EMPLOYED = 365243** | 18% of records | Replace with NA + create indicator flag |
| **Negative day values** | All date columns | Convert to positive years for interpretability |
| **Missing EXT_SOURCE_1** | 56.4% missing | Create missing indicators + composite score |
| **Missing EXT_SOURCE_3** | 19.8% missing | Create missing indicators + mean imputation |
| **Supplementary data** | Millions of rows | Aggregate to applicant level with 64 features |
| **Infinite values** | In ratio calculations | Replace with NA for safe handling |

## ğŸ’¡ Complete Workflow Example

```r
# ============================================
# COMPLETE DATA SCIENCE WORKFLOW
# ============================================

# Step 1: Exploratory Data Analysis
# ----------------------------------
library(quarto)
quarto_render("EDA_homecredit_short.qmd")
# Review HTML output for insights

# Step 2: Feature Engineering
# ----------------------------
source("feature_engineering.R")
data_dir <- "./data"
results <- run_feature_engineering_pipeline(data_dir)

# Step 3: Inspect Processed Data
# -------------------------------
train <- results$train
test <- results$test

# Check dimensions
dim(train)  # 307511 Ã— 219

# Check target distribution
table(train$TARGET)
prop.table(table(train$TARGET))

# View new features
new_features <- c(
  "CREDIT_INCOME_RATIO", "PAYMENT_BURDEN", 
  "BUREAU_ACTIVE_RATIO", "PREV_APPROVAL_RATE",
  "INSTALL_LATE_RATE", "EXT_SOURCE_MEAN"
)
summary(train[, ..new_features])

# Step 4: Handle Remaining Missing Values (Optional)
# --------------------------------------------------
library(mice)
train_imputed <- mice(train, method = "rf", m = 1)

# Step 5: Prepare for Modeling
# -----------------------------
# Encode categorical variables
# Scale numeric features
# Split validation set
# Train models (XGBoost, LightGBM, etc.)
```

## ğŸ”„ Pipeline Functions

The `feature_engineering.R` script contains 6 modular functions:

### 1. `clean_and_engineer_features(df, is_train, train_stats)`
- Fixes DAYS_EMPLOYED anomaly
- Creates demographic features
- Engineers 10 financial ratios

### 2. `add_advanced_features(df)`
- Creates missing value indicators
- Builds interaction terms
- Creates binned variables
- Aggregates document flags

### 3. `aggregate_bureau_features(bureau)`
- Processes bureau credit history
- Returns 23 aggregated features
- Computes credit behavior metrics

### 4. `aggregate_previous_applications(prev_app)`
- Processes previous applications
- Returns 24 aggregated features
- Computes approval/refusal patterns

### 5. `aggregate_installments(installments)`
- Processes payment history
- Returns 17 aggregated features
- Computes late payment metrics

### 6. `run_feature_engineering_pipeline(data_dir, save_output)`
- Master function orchestrating entire pipeline
- Loads all data sources
- Applies all transformations
- Joins aggregated features
- Saves processed files

## ğŸ“Š Performance Metrics

### Memory Usage
- **Peak RAM**: ~4-6 GB (during aggregations)
- **Recommended**: 8 GB+ RAM

### Processing Time (Standard laptop)
- Bureau aggregation: ~40 seconds
- Previous apps aggregation: ~45 seconds
- Installments aggregation: ~11 seconds
- Feature engineering: ~2-3 minutes
- **Total**: ~3-4 minutes

### Output Size
- Training data: 337 MB
- Test data: 55 MB
- Total: ~392 MB

## ğŸ“ Educational Value

This project demonstrates:
- âœ… Professional data science workflow
- âœ… Comprehensive exploratory analysis
- âœ… Feature engineering best practices
- âœ… Data quality management
- âœ… Code documentation and organization
- âœ… Git version control
- âœ… Reproducible research (Quarto)

### Skills Demonstrated
- R programming (data.table, dplyr)
- Statistical analysis
- Data visualization (ggplot2)
- Feature engineering
- Data aggregation at scale
- Documentation writing
- Version control (Git/GitHub)

## ğŸ“š Documentation

| Document | Description | Lines |
|----------|-------------|-------|
| `README.md` | Project overview (this file) | 400+ |
| `README_feature_engineering.md` | Detailed feature specs | 156 |
| `QUICK_REFERENCE.md` | Quick commands | 195 |
| `EDA_homecredit_short.qmd` | Analysis notebook | 1,003 |

## ğŸ¤ Use Cases

This pipeline is suitable for:
- ğŸ“Š Credit default risk prediction
- ğŸ’° Loan approval modeling
- ğŸ‘¥ Customer segmentation
- ğŸ“ˆ Risk scoring systems
- ğŸ“ Feature engineering education
- ğŸ’¼ Portfolio projects
- ğŸ“ Academic assignments

## ğŸ› Troubleshooting

### Common Issues

**Error: File not found**
```r
# Check data directory contents
list.files(data_dir, pattern = "\.csv$")
```

**Error: Out of memory**
```r
# Clear workspace and garbage collect
rm(list = setdiff(ls(), c("train", "test")))
gc()

# Or process files individually
bureau_agg <- aggregate_bureau_features(bureau)
rm(bureau); gc()
```

**Warning: Inf values in ratios**
```r
# Replace infinite values
train <- train %>% 
  mutate(across(where(is.numeric), ~na_if(., Inf))) %>%
  mutate(across(where(is.numeric), ~na_if(., -Inf)))
```

## ğŸ”® Future Enhancements

Potential improvements:
- [ ] Add POS_CASH_balance aggregations
- [ ] Add credit_card_balance features
- [ ] Implement automated feature selection
- [ ] Add cross-validation splits
- [ ] Create model evaluation scripts
- [ ] Build prediction pipeline
- [ ] Add Shiny dashboard for visualization

## ğŸ“ Citation

If you use this code in your work, please cite:

```bibtex
@misc{homecredit2026,
  title={Home Credit Default Risk - Data Preparation Pipeline},
  author={IS6850 Student},
  year={2026},
  publisher={GitHub},
  url={https://github.com/YOUR_USERNAME/home-credit-feature-engineering}
}
```

## ğŸ“„ License

This project is created for educational purposes as part of IS6850 coursework.

**Educational Use Only** - University of Arizona, Spring 2026

## ğŸ‘¤ Author

**IS6850 Student**
- University: University of Arizona
- Course: IS6850 - Applied Data Science
- Semester: Spring 2026
- Date: February 2026

## ğŸ™ Acknowledgments

- **Home Credit Group** for the Kaggle competition dataset
- **IS6850 Course Staff** for guidance and instruction
- **R Community** for data.table, dplyr, and ggplot2
- **Posit** for Quarto and RStudio
- **Kaggle** for hosting the competition and data

## ğŸ“ Contact & Support

- **Repository Issues**: Use GitHub Issues tab
- **Questions**: Contact course instructor
- **Contributions**: Fork and submit pull requests

---

**â­ Star this repository if you find it helpful!**

**ğŸ”— Repository**: [github.com/YOUR_USERNAME/home-credit-feature-engineering](https://github.com/YOUR_USERNAME/home-credit-feature-engineering)

**ğŸ“… Last Updated**: February 8, 2026

---

*Built with â¤ï¸ using R, data.table, and Quarto*

